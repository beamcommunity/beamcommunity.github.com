* Website: http://discoproject.org/
* Responsible: Shayan Pooya, Prashanth Mundkur
* If you have any questions, send an e-mail to beam-community@googlegroups.com.

Ideas are listed in no particular order.

### Idea #1:  Disco worker in more efficient programming languages.

Brief explanation:  The default disco worker is written in Python.  Python is easy to use and there are a lot of tools available for it.  However, there are certain jobs and use-cases that need more efficient languages.  That is why the Disco worker protocol has been abstracted out and some worker protocols in other languages (OCaml and Java) have been created.  The objective of this project is to implement a golang or Haskell worker.  The workers should be general purpose, extensible and it should be simple and flexible to extend these workers to create new workers to do various tasks.

Expected results: A worker in Haskell or golang that can be extended to write different types of workers.

Knowledge prerequisites: Python, Erlang, and golang or Haskell

Mentors: Shayan Pooya, Prashanth Mundkur

### Idea #2:  DDFS testing using Local-Cluster mode.

Brief explanation:  Testing a particular distributed system generally requires significant investment in a distributed testing harness, especially when it comes to supporting _reproducible_ automated tests.  This normally means that testing the fault-tolerance and safety of a distributed filesystem like DDFS requires a fair amount of work.

However, DDFS now has the capability to simulate a cluster in a single machine (the 'local cluster' mode).  This means that we can test the fault-tolerance, garbage collection and replication features of DDFS using a single machine, in an automated and easy-to-reproduce way.

Expected results:  This project would involve writing a testing library and tests that use the local-cluster mode to test GC and replication in DDFS.

Knowledge prerequisites:  Distributed systems, Erlang, Python.

Mentors:  Shayan Pooya, Prashanth Mundkur

### Idea #3:  Improving security of Disco workers

Brief explanation:  Currently, Disco workers run completely untrusted code that has full access to a node's filesystem, and hence also to intermediate data generated by other jobs and any DDFS data on that node.

This project would explore techniques to sandbox the Disco worker process in a manner that is easy to port to exploit sandboxing features supported by different OSes.  The portability should be tested by targeting the implementation at least two of (a) Linux namespaces/containers, (b) MacOSX sandbox(7), (c) FreeBSD Capsicum.

An alternative could be to provide a specialized Disco worker that uses the Google Native Client framework to sandbox.

Expected results:  A prototype of a portable sandboxed Disco worker.

Knowledge prerequisites:  Operating systems, security.

Mentors:  Shayan Pooya, Prashanth Mundkur

### Idea #4:  Property testing of the pipelined job scheduler

Brief explanation:  The new Disco job scheduler was explicitly written in a way to make it easy to test with Erlang's property testing tools like Proper/Triq/Quickcheck.  There are already some basic tests for low-level functionality.  This project would create property tests that eventually cover the entire pipeline scheduling code.

There are other areas of Disco that could also benefit from modularized property testing that the applicant could choose to work on.

Expected results:  A property-testing test suite.

Knowledge prerequisites:  Erlang.

Mentors:  Shayan Pooya, Prashanth Mundkur

### Idea #5:  Network-resource-aware task allocator

Brief explanation:  The current mechanism of allocating tasks to cluster nodes uses a very naive idea of the network topology of the cluster, especially of the rack-locality of cluster nodes.  It would be good to address this taking into account the dynamic network topology present in an environment like AWS (as opposed to assuming a static environment).

There are two components for this project: (a) infer or extract the current cluster network topology while requiring the absolute minimum of user-configuration (ideally none), and (b) exploiting this network topology in a new task allocator algorithm that minimizes network impact of task allocations.

A stretch goal would be to also use this topology in DDFS to minimize network impact of replication and improving replica placement to handle rack-level outages.

Expected results:  A prototype for an improved network-aware task scheduler.

Knowledge prerequisites:  Networking, Erlang.

Mentors:  Shayan Pooya, Prashanth Mundkur


### Idea #6: Disco on top of other distributed filesystems

Brief explanation:  Disco has its own distributed filesystem called DDFS.  However, there is no inherent coupling between disco and ddfs.  Disco can be modified to work on top of different filesystems like HDFS or RamCloud.  A mechanism should be designed and implemented for supporting the concept of DDFS TAGs on HDFS or RamCloud.

Expected results:  A working version of Disco which uses filesystems like HDFS for reading and storing data.  There should be a configuration option that lets disco choose between the underlying filesystems.  This new filesystem should be fault tolerant and should read and use the same configuration options for DDFS.


Knowledge prerequisites:  Distributed Systems, Erlang, File Systems, Fault tolerance.

Mentors:  Shayan Pooya, Prashanth Mundkur



### Idea #7: New features for Disco front end.

There are a couple of features that should be added to Disco front end.

1. Role based authentication for Disco:
Disco needs a mechanism to separate its users and limit the interference between them.  For example, a user should be able to kill her own job but not other people's jobs; Only the administrators should be able to kill all of the jobs.

2. We should limit the amount of resources each webpage use and de-prioritize them versus the the internal calls of Disco.

3. Each user should only see the jobs launched by herself.  Only an admin should be able to see the GC statistics and change the configurations of Disco.

4. Disco needs a better mechanism for searching through the events of the jobs.  In its current form, doing such searches puts a lot of pressure on disco master.

Knowledge prerequisites:  Erlang, HTTP, html/javascript/css

Mentors: Shayan Pooya, Prashanth Mundkur


### Idea #8: Add namespace to DDFS.
Currently all of the tags in ddfs are stored in the same namespace a lot of operations are per tag.  In order to improve the scalability and usability of ddfs, we can add the namespace meta-data to the tags.  This namespace can be used for determining which directory should be used for storing the blobs of a tag.  For example, the file of the namespace temp/test can be stored in the ddfs/temp/test directory (Although the first iteration does not have to support sub namespaces like this).  With this approach, some of the ddfs operations will get much cheaper.  For example, a ddfs ls will be a per namespace and there is much less work to do.  The most important win, however, will be the garbage collection.  Disco can start and finish the gc on one namespace before starting on the next one and therefore reducing the amount of time (and pressure on the system) that gc takes.

Knowledge prerequisites: Erlang

Mentors: Shayan Pooya, Prashanth Mundkur
